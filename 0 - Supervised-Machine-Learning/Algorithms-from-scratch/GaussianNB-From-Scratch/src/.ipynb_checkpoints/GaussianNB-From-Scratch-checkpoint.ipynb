{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recoding a GaussianNB from scratch\n",
    "\n",
    "![](https://images.unsplash.com/photo-1530639834082-05bafb67fbbe?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this notebook, we will recode the Gaussian Naive Bayes algorithm **from scratch**. <br>\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "A quick reminder on **Naive Bayes classification** :\n",
    "1. The NB classifier is based on the **Bayes Theorem** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Pr(Y=y_k | X=x) = \\frac{Pr(X=x | Y-y_k)Pr(Y=y_k)}{Pr(X=x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above formula :\n",
    "- $Pr(Y=y_k|X=x)$ is **the probability of each class given the known features**\n",
    "- $Pr(X=x|Y=y_k)$ is **the probability of the features given the class**\n",
    "- $Pr(Y=y_k)$ is **the probability of apparition of the class on the given dataset**\n",
    "- $Pr(X=x)$ **does not actually need to be computed**\n",
    "\n",
    "Using the Bayes formula, **the algorithm computes the probability of each class for a given set of features, and returns the class with the higest computed probability**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $Pr(Y=y_k)$, the probability of apparition of the class on the given dataset, is very easy to compute : it is just **the percentage of apparition on each class on the training set**.\n",
    "\n",
    "3. $Pr(X=x|Y=y_k)$, the probability of the features given the class, is a little bit harder to compute, but no stress, let's go step by step :\n",
    "- The probability of all features given the class is equal to the product of **the probability of each single feature given the class**.\n",
    "- And **the probability of each single feature given the class can be computed using the following (gaussian) formula** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(x_i \\mid Y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_Y}} \\exp\\left(-\\frac{(x_i - \\mu_Y)^2}{2\\sigma^2_Y}\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above formula :\n",
    "- $\\mu_k$ is the mean of the feature $x$ for a given class $y_k$\n",
    "- $\\sigma_k$ is the standard deviation of the feature $x$ for a given class $y_k$\n",
    "\n",
    "⚠️ **The values of $\\mu$, $\\sigma$, and the probability of apparition on each class over the training dataset is what the algorithm learns during the fitting stage.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. From scratch implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Creating the `GaussianNaiveBayes` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T12:21:26.405489Z",
     "start_time": "2020-07-07T12:21:26.390379Z"
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes():\n",
    "    \n",
    "    def _get_target_proba(self, y, target):\n",
    "        \"\"\"\n",
    "        Returns the probability of apparition of a given target on a given dataset,\n",
    "        e.g. the percentage of representation of the given target over the dataset.\n",
    "        \n",
    "        Parameters\n",
    "            y {np.ndarray} -- the target array (1-dimensional)\n",
    "            target {int} -- the given target\n",
    "            \n",
    "        Returns\n",
    "            float : the proportion of representation of the given target over the dataset.\n",
    "        \"\"\"\n",
    "        proba = y[y == target].size / y.size\n",
    "        return proba\n",
    "    \n",
    "    \n",
    "    def _get_mu(self, X, y, target):\n",
    "        \"\"\"\n",
    "        Returns the mean of each feature of a dataset for all observations corresponding to a given target.\n",
    "        \n",
    "        Parameters\n",
    "            X {np.ndarray} -- the features array (n-dimensional)\n",
    "            y {np.ndarray} -- the target array (1-dimensional)\n",
    "            target {int} -- the given target\n",
    "            \n",
    "        Returns\n",
    "            np.ndarray (1-dim) : the mean value of each feature in the dataset for the given target.\n",
    "        \"\"\"\n",
    "        mu = X[y == target].mean(axis = 0)\n",
    "        return mu\n",
    "    \n",
    "    \n",
    "    def _get_sigma(self, X, y, target):\n",
    "        \"\"\"\n",
    "        Returns the standard deviation of each feature of a dataset for all observations corresponding to a given target.\n",
    "        \n",
    "        Parameters\n",
    "            X {np.ndarray} -- the features array (n-dimensional)\n",
    "            y {np.ndarray} -- the target array (1-dimensional)\n",
    "            target {int} -- the given target\n",
    "            \n",
    "        Returns\n",
    "            np.ndarray (1-dim) : the standard deviation of each feature in the dataset for the given target.\n",
    "        \"\"\"\n",
    "        sigma = X[y == target].std(axis = 0)\n",
    "        return sigma \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits the algorithm, e.g. storing as attributes :\n",
    "            > self.target_probas -- the probability of apparition of each target\n",
    "            > self.mus -- the mean of each feature for each target\n",
    "            > self.sigma -- the standard deviation of each feature for each target\n",
    "        \"\"\"\n",
    "        self.target_probas = np.array([self._get_target_proba(y, target) for target in list(set(y))])\n",
    "        self.mus = np.array([self._get_mu(X, y, target) for target in list(set(y))])\n",
    "        self.sigmas = np.array([self._get_sigma(X, y, target) for target in list(set(y))])\n",
    "        \n",
    "        \n",
    "    def _get_single_feature_probability(self, x, mu, sigma):\n",
    "        \"\"\"\n",
    "        Returns the probability of apparition of a single feature, given the target.\n",
    "        Uses the Gaussian probabilistic law.\n",
    "        \n",
    "        Parameters\n",
    "            x {float} -- a single point from a single feature\n",
    "            mu {float} -- the mean of the feature from which x comes\n",
    "            sigma {float} -- the standard deviation of the feature from which x comes\n",
    "            \n",
    "        Returns\n",
    "            float : the probability of a single feature point, for a given target.\n",
    "        \"\"\"\n",
    "        feature_proba = 1 / (math.sqrt(2 * math.pi)) * math.e**(-(x-mu)**2/(2*sigma**2))\n",
    "        return feature_proba\n",
    "    \n",
    "    \n",
    "    def _predict_single_x(self, x):\n",
    "        \"\"\"\n",
    "        Returns the probabilities of belonging to each of the target class for a given data point.\n",
    "        \n",
    "        Parameters\n",
    "            x {np.ndarray} -- a single observation from the dataset (1-dimensional)\n",
    "            \n",
    "        Returns\n",
    "            np.ndarray (1-dimensional) : the array of probabilities of each class for a single point.\n",
    "        \"\"\"\n",
    "        single_proba = np.prod(self._get_single_feature_probability(x, self.mus, self.sigmas), axis = 1) * self.target_probas\n",
    "        return single_proba\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Returns the probabilities of belonging to each of the target class for all points of the dataset.\n",
    "        \n",
    "        Parameters\n",
    "            X {np.ndarray} -- the dataset (2-dimensional)\n",
    "            \n",
    "        Returns \n",
    "            np.ndarray (2-dimensional) : the array of probabilities of each class for each point in the dataset.\n",
    "        \"\"\"\n",
    "        predict_probas = np.array([self._predict_single_x(x) for x in X])\n",
    "        return predict_probas\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns the predicted class for all points of the dataset.\n",
    "        \n",
    "        Parameters\n",
    "            X {np.ndarray} -- the dataset (2-dimensional)\n",
    "            \n",
    "        Returns \n",
    "            np.ndarray (1-dimensional) : the predicted class for each point in the dataset.\n",
    "        \"\"\"\n",
    "        pred_proba = self.predict_proba(X)\n",
    "        pred_class = np.array([np.argmax(pred_proba[i]) for i in range(X.shape[0])])\n",
    "        \n",
    "        return pred_class\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Returns the accuracy score for the model on the dataset X, y.\n",
    "        \n",
    "        Parameters\n",
    "            X {np.ndarray} -- the dataset (2-dimensional)\n",
    "            y {np.ndarray} -- the target (1-dimensional)\n",
    "        \n",
    "        Returns\n",
    "            float : accuracy score of the model.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Testing your model on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_df = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris_df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris_df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.31517245e-100, 1.88620105e-004, 1.00968505e-004],\n",
       "       [4.14903905e-141, 9.92423656e-006, 1.06334270e-003],\n",
       "       [2.07325099e-106, 4.49417601e-004, 4.33418654e-004],\n",
       "       [6.96925037e-003, 1.54697093e-019, 1.13275093e-025],\n",
       "       [3.46789709e-130, 5.64866570e-005, 2.64850486e-003],\n",
       "       [1.71154769e-037, 2.21362748e-005, 1.09389726e-011],\n",
       "       [1.16802207e-096, 8.20501523e-004, 1.77421963e-004],\n",
       "       [7.22712431e-003, 3.80752648e-019, 4.44982720e-025],\n",
       "       [2.39349168e-267, 6.81487337e-019, 4.87790708e-006],\n",
       "       [2.21387696e-003, 4.36311495e-020, 5.48789768e-026],\n",
       "       [7.46738490e-003, 2.75053092e-019, 3.01721083e-025],\n",
       "       [6.12479256e-176, 5.54608556e-009, 6.82207798e-003],\n",
       "       [3.48966897e-004, 1.37247559e-017, 2.35156894e-023],\n",
       "       [5.26901409e-152, 3.50776032e-007, 4.53727163e-003],\n",
       "       [2.14650760e-003, 2.42302080e-016, 6.58196233e-023],\n",
       "       [1.76998679e-114, 9.65217686e-004, 1.85985751e-004],\n",
       "       [3.06474753e-095, 3.39997590e-003, 1.26540570e-004],\n",
       "       [3.28984779e-003, 2.23238057e-020, 9.85940717e-027],\n",
       "       [9.27286279e-075, 6.59054394e-003, 2.85789341e-006],\n",
       "       [1.18935434e-155, 3.30644089e-006, 4.20037986e-003],\n",
       "       [3.08534252e-003, 7.30050488e-018, 3.09551275e-024],\n",
       "       [1.32796606e-074, 6.38291386e-003, 5.52723243e-006],\n",
       "       [1.06045434e-079, 5.86787274e-003, 1.97156705e-005],\n",
       "       [5.07272736e-003, 1.76525893e-019, 8.46282088e-026],\n",
       "       [7.94911916e-060, 3.48415584e-004, 5.29299982e-009],\n",
       "       [4.55374970e-003, 1.47825085e-019, 2.19016388e-025],\n",
       "       [1.56610103e-184, 1.42964994e-008, 6.69159857e-003],\n",
       "       [9.99368642e-071, 4.41553108e-003, 2.79732774e-006],\n",
       "       [8.10847556e-144, 1.22599458e-005, 1.51348728e-003],\n",
       "       [9.00764495e-146, 2.11395679e-006, 4.67503109e-004]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing the sklearn version of the GaussianNB on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb2 = GaussianNB()\n",
    "gnb2.fit(X_train, y_train)\n",
    "y_pred = gnb2.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are the same between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
