{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baby name\n",
    "\n",
    "![](https://images.unsplash.com/photo-1519689680058-324335c77eba?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge, you will generate baby names using recurrent neural networks!\n",
    "\n",
    "The used dataset is in the file `names.txt`, a file encoded in `'ISO-8859-1'`, containing more than 10 000 names.\n",
    "\n",
    "First load it, and have a look at the names, and clean the dataset if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = pd.read_csv('../input/names.txt', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaliyah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aapeli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aapo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aarne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11611</th>\n",
       "      <td>zvi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11612</th>\n",
       "      <td>zvonimir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>zvonimira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11614</th>\n",
       "      <td>zvonko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11615</th>\n",
       "      <td>zygmunt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11616 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name\n",
       "0        aaliyah\n",
       "1         aapeli\n",
       "2           aapo\n",
       "3          aaren\n",
       "4          aarne\n",
       "...          ...\n",
       "11611        zvi\n",
       "11612   zvonimir\n",
       "11613  zvonimira\n",
       "11614     zvonko\n",
       "11615    zygmunt\n",
       "\n",
       "[11616 rows x 1 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RNN needs to understand where is the beginning and the end of a word. So we need to add a new character at the beginning of every word, for example `'\\t'` (it could be anything else as long as it can be identified easily). We can also add `'\\n'` to the end of every word as the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:23.225522Z",
     "start_time": "2019-12-01T21:47:23.221309Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: add '\\t' at the beginning of every word\n",
    "names = names.name.apply(lambda x: \"\\t\" + x + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate names, we will have to play at the character level: we will train a RNN to predict the next character, knowing the previous one. So, compute a list of all the possible characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:26.174071Z",
     "start_time": "2019-12-01T21:47:26.169615Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Compute and display the list of all possible characters\n",
    "characters = set([c for word in names.values for c in word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get 55 characters, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual when playing with characters (or words), we will convert them into integers. So build a dictionary `char_to_idx` that, given a character as key, returns an integer. And build the opposite dictionary `idx_to_char` that, given an integer as key, returns the corresponding character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:29.211404Z",
     "start_time": "2019-12-01T21:47:29.207022Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Compute the idx_to_char and char_to_idx dict\n",
    "char_to_idx = {}\n",
    "i = 0\n",
    "for char in characters:\n",
    "    char_to_idx[char] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {v: k for k, v in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into the neural network part, we have one more step: **create the X and y data**!\n",
    "\n",
    "So the **X** data is going to be, for every name, all but the `'\\n'` character. The **y** data will be all but the `'\\t'` character.\n",
    "\n",
    "Indeed, we will try to predict the following character knowing the previous. To the **X** does not need the final character, and the **y** does not need the first character.\n",
    "\n",
    "Create the columns X and y to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:32.481406Z",
     "start_time": "2019-12-01T21:47:32.477073Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Create the columns X and y\n",
    "X = names.apply(lambda x: x[:-1])\n",
    "y = names.apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using your `char_to_idx` dict, compute the corresponding `X` and `y` containing, for each name, a list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:35.283290Z",
     "start_time": "2019-12-01T21:47:35.278008Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create the X and y variables containing integers only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: [char_to_idx[c] for c in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.apply(lambda x: [char_to_idx[c] for c in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was complicated, but are now in a known case, use keras and `pad_sequence()` function to get a proper `X` and `y` variables with a `maxlen=16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:38.374154Z",
     "start_time": "2019-12-01T21:47:38.369594Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Use pad_sequences to get only sequences of length 16 for each name\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "X = sequence.pad_sequences(X,\n",
    "                           value=char_to_idx['\\n'],\n",
    "                           padding='post', # to add zeros at the end\n",
    "                           truncating='post', # to cut the end of long sequences\n",
    "                           maxlen=16) # the length we want\n",
    "\n",
    "y = sequence.pad_sequences(y,\n",
    "                           value=char_to_idx['\\n'],\n",
    "                           padding='post', # to add zeros at the end\n",
    "                           truncating='post', # to cut the end of long sequences\n",
    "                           maxlen=16) # the length we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using the function `to_categorical()`, make the one-hot-encoding needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:41.491778Z",
     "start_time": "2019-12-01T21:47:41.487157Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: use to_categorical to perform one hot encoding\n",
    "X = tf.keras.utils.to_categorical(X)\n",
    "y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should finally have arrays of shape `(number of names, 16, 55)`:\n",
    "- `16` is the sequence length\n",
    "- `55` is the number of possible characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11616, 16, 55)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11616, 16, 55)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have to build a neural network. You can for example use one or two layers of GRU (or LSTM). Do not forget to set `return_sequences=True`. \n",
    "\n",
    "Then you will have to add a `TimeDistributed(Dense(55))` with a softmax activation function. This layer will handle the fact you have a dense layer at each time step with a softmax prediction of the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-01T21:47:45.220935Z",
     "start_time": "2019-12-01T21:47:45.216190Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Build the neural network\n",
    "def name_RNN():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(GRU(units=32, activation='relu', return_sequences=True))\n",
    "    model.add(GRU(units=32, activation='relu', return_sequences=True))\n",
    "  \n",
    "    model.add(TimeDistributed(Dense(55, activation='softmax')))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = name_RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(patience=10, restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "146/146 [==============================] - 3s 19ms/step - loss: 2.1130 - accuracy: 0.5850 - val_loss: 1.3744 - val_accuracy: 0.6403\n",
      "Epoch 2/10\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.3179 - accuracy: 0.6434 - val_loss: 1.2648 - val_accuracy: 0.6467\n",
      "Epoch 3/10\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.2394 - accuracy: 0.6488 - val_loss: 1.2074 - val_accuracy: 0.6583\n",
      "Epoch 4/10\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 1.1862 - accuracy: 0.6590 - val_loss: 1.1681 - val_accuracy: 0.6619\n",
      "Epoch 5/10\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 1.1590 - accuracy: 0.6615 - val_loss: 1.1470 - val_accuracy: 0.6617\n",
      "Epoch 6/10\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.1407 - accuracy: 0.6620 - val_loss: 1.1335 - val_accuracy: 0.6622\n",
      "Epoch 7/10\n",
      "146/146 [==============================] - 2s 17ms/step - loss: 1.1282 - accuracy: 0.6630 - val_loss: 1.1260 - val_accuracy: 0.6633\n",
      "Epoch 8/10\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 1.1201 - accuracy: 0.6635 - val_loss: 1.1172 - val_accuracy: 0.6647\n",
      "Epoch 9/10\n",
      "146/146 [==============================] - 3s 17ms/step - loss: 1.1132 - accuracy: 0.6646 - val_loss: 1.1121 - val_accuracy: 0.6645\n",
      "Epoch 10/10\n",
      "146/146 [==============================] - 3s 18ms/step - loss: 1.1085 - accuracy: 0.6662 - val_loss: 1.1066 - val_accuracy: 0.6652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff263507910>"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size= 64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step will be to generate names, through a function `generate_names()`. \n",
    "\n",
    "To do so, you will have to give the output of the previous time step prediction as input to the next time step.\n",
    "\n",
    "You will have to use the method `predict_proba` of your model, as will as the method `numpy.random.choice`.\n",
    "\n",
    "Finally, use your function to generate some names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.87666453e-02, 4.04689526e-05, 5.01026152e-05, 2.20640097e-03,\n",
       "       3.23441607e-04, 3.12255532e-03, 2.71252333e-03, 5.36873983e-07,\n",
       "       1.95922068e-04, 3.64679909e-05, 3.15676220e-06, 1.67048629e-03,\n",
       "       2.55207706e-05, 2.24082596e-05, 2.76832134e-06, 1.23888913e-05,\n",
       "       4.21849824e-03, 5.65304690e-05, 8.92294012e-03, 2.55219522e-04,\n",
       "       4.49251290e-03, 1.28716332e-04, 9.89208370e-03, 5.37380949e-03,\n",
       "       1.00988123e-04, 1.91884556e-05, 1.63284466e-02, 2.73219612e-05,\n",
       "       4.64622444e-03, 3.52850257e-05, 3.57403391e-04, 7.31596909e-03,\n",
       "       2.22575013e-02, 3.14246655e-01, 5.49622206e-03, 4.65169287e-05,\n",
       "       8.52178559e-02, 1.84275322e-02, 7.46846106e-03, 1.59478765e-02,\n",
       "       1.73325818e-02, 2.76729371e-03, 8.05831049e-03, 1.93544406e-06,\n",
       "       3.34900199e-03, 4.73601716e-07, 1.26681434e-05, 1.20163031e-01,\n",
       "       2.75831044e-01, 2.28373581e-04, 6.65775547e-03, 1.02337486e-04,\n",
       "       4.77080030e-05, 2.94019608e-03, 2.03564437e-03], dtype=float32)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = []\n",
    "for l in model.predict(X_test)[5]:\n",
    "    idx = np.argmax(l)\n",
    "    word.append(idx_to_char[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_test = []\n",
    "for l in X_test[5]:\n",
    "    idx = np.argmax(l)\n",
    "    word_test.append(idx_to_char[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t',\n",
       " 'h',\n",
       " 'y',\n",
       " 'l',\n",
       " 'e',\n",
       " 'd',\n",
       " 'd',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " 'n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_names(n, max_len, char_to_idx, model):\n",
    "    \"\"\"\n",
    "    Generate n names automatically\n",
    "    \n",
    "    Returns:\n",
    "\n",
    "    parameters:\n",
    "    -- n: the number of names to generate (int)\n",
    "    -- max_len: the length of the sequence\n",
    "    -- char_to_idx: the dict giving the char corresponding to each idx\n",
    "    -- model: the trained model that will be used to generate names\n",
    "    \"\"\"\n",
    "    for _ in range(n):\n",
    "        stop=False\n",
    "        ch='\\t'\n",
    "        counter=1\n",
    "        target_seq = np.zeros((1, max_len, len(char_to_idx)))\n",
    "        target_seq[0, 0, char_to_idx[ch]] = 1.\n",
    "        while stop == False and counter < 10:\n",
    "            #sample the data\n",
    "            probs = model.predict_proba(target_seq, verbose=0)[:,counter-1,:]\n",
    "            c = np.random.choice(list(char_to_idx.keys()), replace =False, p=probs.reshape(len(char_to_idx)))\n",
    "            if c=='\\n':\n",
    "                stop=True\n",
    "            else:\n",
    "                ch=ch+c\n",
    "                target_seq[0, counter ,char_to_idx[c]] = 1.\n",
    "                counter=counter+1\n",
    "        print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\traévan\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 1 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-5df635875864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_n_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-290-2f5a7ea35460>\u001b[0m in \u001b[0;36mgenerate_n_names\u001b[0;34m(n, max_len, char_to_idx, model)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mchar_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mcounter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"
     ]
    }
   ],
   "source": [
    "generate_n_names(10, 8, char_to_idx, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case this looks too complicated (indeed it is far from being simple), you can use the function `generate_n_names()` in the file `generate.py`. But first have a look at it and try to understand what it does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have more time, you can try to improve the results by tuning your neural network hyperparameters.\n",
    "\n",
    "You can also use the original file, `Prenoms.csv`, and use only names from a given origin, to build a model more specific for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: This method can be applied to almost anything: you can generate music, shakespeare, lyrics... using this method. All it takes is to change the data preprocessing and adapt the dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
