{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1512436991641-6745cdb1723f?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "Photo by [Lauren Fleischmann](https://unsplash.com/photos/R2aodqJn3b8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 10 classes:\n",
    "* 0:\tT-shirt/top\n",
    "* 1:\tTrouser\n",
    "* 2:\tPullover\n",
    "* 3:\tDress\n",
    "* 4:\tCoat\n",
    "* 5:\tSandal\n",
    "* 6:\tShirt\n",
    "* 7:\tSneaker\n",
    "* 8:\tBag\n",
    "* 9:\tAnkle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now begin by exploring the data. Try to display some images with the associated label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Explore the data, display some input images\n",
    "\n",
    "size = 4\n",
    "sample_graph = np.random.randint(0,60000, size)\n",
    "\n",
    "sample_images = X_train[sample_graph]\n",
    "sample_labels = y_train[sample_graph]\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "\n",
    "ax =[]\n",
    "\n",
    "for i in range(1,size+1):\n",
    "    ax.append(plt.subplot(size // 4 + 1,4,i))\n",
    "    plt.imshow(sample_images[i-1].reshape((28,28)), cmap='gray_r')\n",
    "    ax[i-1].title.set_text(labels_map[sample_labels[i-1]])\n",
    "    ax[i-1].set_xticks([])\n",
    "    ax[i-1].set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before going further**: what methods could you use to perform such a classification task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could use any classification model (KNN, LogisticRegression, Trees, Forests,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
    "\n",
    "Hint: you can use the Keras function `to_categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make the data preparation\n",
    "X_train_rs = X_train.reshape(X_train.shape[0], -1) / 255\n",
    "X_test_rs = X_test.reshape(X_test.shape[0], -1) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build your model\n",
    "def multilayer_perceptron(input_dim):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(50, input_dim=input_dim, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Compile and fit your model\n",
    "model = multilayer_perceptron(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8579 - val_loss: 0.4429 - val_accuracy: 0.8414\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8569 - val_loss: 0.4434 - val_accuracy: 0.8420\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8580 - val_loss: 0.4520 - val_accuracy: 0.8386\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8580 - val_loss: 0.4451 - val_accuracy: 0.8435\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4018 - accuracy: 0.8589 - val_loss: 0.4404 - val_accuracy: 0.8426\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8585 - val_loss: 0.4395 - val_accuracy: 0.8446\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8593 - val_loss: 0.4432 - val_accuracy: 0.8418\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8601 - val_loss: 0.4376 - val_accuracy: 0.8452\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8609 - val_loss: 0.4361 - val_accuracy: 0.8437\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8600 - val_loss: 0.4370 - val_accuracy: 0.8453\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8618 - val_loss: 0.4318 - val_accuracy: 0.8470\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8623 - val_loss: 0.4314 - val_accuracy: 0.8464\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8619 - val_loss: 0.4356 - val_accuracy: 0.8452\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8622 - val_loss: 0.4319 - val_accuracy: 0.8482\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3892 - accuracy: 0.8636 - val_loss: 0.4293 - val_accuracy: 0.8487\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8635 - val_loss: 0.4313 - val_accuracy: 0.8481\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8640 - val_loss: 0.4372 - val_accuracy: 0.8464\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8627 - val_loss: 0.4646 - val_accuracy: 0.8355\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3874 - accuracy: 0.8640 - val_loss: 0.4298 - val_accuracy: 0.8473\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8656 - val_loss: 0.4435 - val_accuracy: 0.8417\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.8656 - val_loss: 0.4271 - val_accuracy: 0.8498\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8655 - val_loss: 0.4215 - val_accuracy: 0.8512\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8659 - val_loss: 0.4219 - val_accuracy: 0.8513\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8675 - val_loss: 0.4211 - val_accuracy: 0.8500\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8673 - val_loss: 0.4188 - val_accuracy: 0.8513\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8666 - val_loss: 0.4221 - val_accuracy: 0.8507\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8666 - val_loss: 0.4195 - val_accuracy: 0.8513\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3762 - accuracy: 0.8682 - val_loss: 0.4167 - val_accuracy: 0.8533\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8675 - val_loss: 0.4161 - val_accuracy: 0.8525\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 0s 4ms/step - loss: 0.3755 - accuracy: 0.8683 - val_loss: 0.4154 - val_accuracy: 0.8549\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8677 - val_loss: 0.4186 - val_accuracy: 0.8514\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8699 - val_loss: 0.4156 - val_accuracy: 0.8544\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8684 - val_loss: 0.4226 - val_accuracy: 0.8492\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3725 - accuracy: 0.8692 - val_loss: 0.4412 - val_accuracy: 0.8432\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8696 - val_loss: 0.4123 - val_accuracy: 0.8540\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8712 - val_loss: 0.4127 - val_accuracy: 0.8543\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8700 - val_loss: 0.4111 - val_accuracy: 0.8546\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8720 - val_loss: 0.4138 - val_accuracy: 0.8534\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8717 - val_loss: 0.4083 - val_accuracy: 0.8552\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.8719 - val_loss: 0.4150 - val_accuracy: 0.8536\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.8719 - val_loss: 0.4082 - val_accuracy: 0.8557\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8717 - val_loss: 0.4089 - val_accuracy: 0.8543\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3635 - accuracy: 0.8723 - val_loss: 0.4135 - val_accuracy: 0.8538\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8722 - val_loss: 0.4119 - val_accuracy: 0.8547\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8728 - val_loss: 0.4330 - val_accuracy: 0.8478\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8731 - val_loss: 0.4069 - val_accuracy: 0.8566\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8751 - val_loss: 0.4046 - val_accuracy: 0.8569\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8737 - val_loss: 0.4059 - val_accuracy: 0.8560\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3592 - accuracy: 0.8740 - val_loss: 0.4058 - val_accuracy: 0.8567\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8738 - val_loss: 0.4031 - val_accuracy: 0.8567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f707c2243d0>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_rs, y_train_cat, epochs=50, batch_size=500, validation_data=(X_test_rs, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 989us/step - loss: 0.4031 - accuracy: 0.8567\n",
      "1875/1875 [==============================] - 2s 980us/step - loss: 0.3525 - accuracy: 0.8757\n",
      "Test accuracy:  0.8567000031471252\n",
      "Train accuracy:  0.8756833076477051\n"
     ]
    }
   ],
   "source": [
    "loss_test, test_acc = model.evaluate(X_test_rs, y_test_cat)\n",
    "loss_train, train_acc = model.evaluate(X_train_rs, y_train_cat)\n",
    "\n",
    "print('Test accuracy: ', test_acc)\n",
    "print('Train accuracy: ', train_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
    "\n",
    "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the accuracy of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
    "\n",
    "You should try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you will perform hyperparameter optimization using a gridsearch on that model!\n",
    "\n",
    "Fit your model and display the performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Redo the classification with PCA and classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_rs)\n",
    "X_test_pca = pca.transform(X_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.886"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the neural network improve significantly the performances? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('pca', PCA()),('estimator', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'pca__n_components':[100, 200, 300],\n",
    "             'estimator__C': [0.01, 1, 10, 100],\n",
    "             'estimator__gamma': ['auto', 'scale']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train_rs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
